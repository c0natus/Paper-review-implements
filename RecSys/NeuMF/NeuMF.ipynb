{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_base = os.path.join(os.path.join('/opt','ml','paper','RecSys'))\n",
    "dir_data = os.path.join(dir_base, 'Data', 'ml-latest-small')\n",
    "path_rating = os.path.join(dir_data, 'ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating = pd.read_csv(path_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(df: pd.DataFrame) -> Tuple[pd.DataFrame, LabelEncoder, LabelEncoder]:\n",
    "    userId_label_encoder = LabelEncoder()\n",
    "    movieId_label_encoder = LabelEncoder()\n",
    "\n",
    "    df['userId'] = userId_label_encoder.fit_transform(df['userId'].values)\n",
    "    df['movieId'] = movieId_label_encoder.fit_transform(df['movieId'].values)\n",
    "\n",
    "    # encoder.inverse_transform() 으로 decode\n",
    "    return df, userId_label_encoder, movieId_label_encoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rating, user_encoder, movie_encoder = encode(df_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainTestSplit(df: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Splits our original data into one test and one\n",
    "    training set. \n",
    "    The test set is made up of one item for each user. This is\n",
    "    our holdout item used to compute Top@K later.\n",
    "    The training set is the same as our original data but\n",
    "    without any of the holdout items.\n",
    "    Args:\n",
    "        df (dataframe): Our original data\n",
    "    Returns:\n",
    "        df_train (dataframe): All of our data except holdout items\n",
    "        df_test (dataframe): Only our holdout items.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create two copies of our dataframe that we can modify\n",
    "    df_test = df.copy(deep=True)\n",
    "    df_train = df.copy(deep=True)\n",
    "\n",
    "    # Group by userId and select only the first item for\n",
    "    # each user (our holdout).\n",
    "    df_test = df_test.groupby(['userId']).first()\n",
    "    df_test['userId'] = df_test.index\n",
    "    df_test = df_test[['userId', 'movieId', 'rating', 'timestamp']]\n",
    "    df_test.index.name = None\n",
    "\n",
    "    # Remove the same items as we for our test set in our training set.\n",
    "    mask = df.groupby(['userId'])['userId'].transform(maskFirst).astype(bool)\n",
    "    df_train = df.loc[mask]\n",
    "\n",
    "    return df_train, df_test\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskFirst(x):\n",
    "    \"\"\"\n",
    "    Return a list of 0 for the first item and 1 for all others\n",
    "    \"\"\"\n",
    "    result = np.ones_like(x)\n",
    "    result[0] = 0\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = trainTestSplit(df_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNegatives(df_train: pd.DataFrame, df_test: pd.DataFrame, set_all_movies: set) -> pd.DataFrame:\n",
    "    list_negative = []\n",
    "\n",
    "    test_user = df_test['userId'].values.tolist()\n",
    "    test_movie = df_test['movieId'].values.tolist()\n",
    "\n",
    "    for user, movie in zip(test_user, test_movie):\n",
    "        list_train_user_movies = df_train[df_train['userId']==user]['movieId'].tolist()\n",
    "        set_pos_user_movies = set(list_train_user_movies + [movie])\n",
    "        list_user_neg_movies = list(set_all_movies - set_pos_user_movies)\n",
    "        \n",
    "        negatives = [user, movie] + np.random.choice(list_user_neg_movies, 99, replace=False).tolist()\n",
    "        list_negative.append(negatives)\n",
    "\n",
    "    df_neg = pd.DataFrame(list_negative)\n",
    "\n",
    "    return df_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of all movies\n",
    "set_all_movies = set(df_rating['movieId'].unique())\n",
    "\n",
    "df_test_neg = getNegatives(df_train, df_test, set_all_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuMFDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, latent_dim, reg=[0, 0]):\n",
    "        super(GMF, self)__init__()\n",
    "\n",
    "        self.MF_embedding_user = nn.Embedding(num_users, latent_dim)\n",
    "        self.NF_embedding_item = nn.Embedding(num_items, latent_dim)\n",
    "\n",
    "        self.prediction = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, user_input, item_input):\n",
    "        user_latent = self.MF_embedding_user(user_input)\n",
    "        item_latent = self.MF_embedding_item(item_input)\n",
    "\n",
    "        product = user_latent * item_latent\n",
    "\n",
    "        output = self.\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
