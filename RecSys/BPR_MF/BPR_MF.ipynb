{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from box import Box\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from typing import Tuple\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setSeed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_base = os.path.join(os.path.join('/opt','ml','paper','RecSys'))\n",
    "dir_data = os.path.join(dir_base, 'Data', 'ml-latest-small')\n",
    "path_rating = os.path.join(dir_data, 'ratings.csv')\n",
    "dir_file_path = {\n",
    "    'dir_base': dir_base,\n",
    "    'dir_data': dir_data,\n",
    "    'path_rating': path_rating,\n",
    "}\n",
    "\n",
    "dir_file_path = Box(dir_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataInfo():\n",
    "    def __init__(self, file_path: str) -> None:\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.user_encoder, self.movie_encoder = self._encode()\n",
    "\n",
    "        self.set_users = set(self.df['userId'].unique())\n",
    "        self.num_users = len(self.set_users)\n",
    "        self.min_feedback = 5 # for resolving cold-start problem\n",
    "        self.set_movies = set(self.df['movieId'].unique())\n",
    "        self.num_movies = len(self.set_movies)\n",
    "        self.set_train_movies = self._moreThanFeedback()\n",
    "        self.num_train_movies = len(self.set_train_movies)\n",
    "\n",
    "        self.user_negative_samples = self._makeNeg()      \n",
    "\n",
    "\n",
    "    def _moreThanFeedback(self):\n",
    "        movie_ids_for_training = list()\n",
    "        for movie_id in self.df['movieId'].unique():\n",
    "            if self.df[self.df['movieId'] == movie_id].shape[0] >= self.min_feedback:\n",
    "                movie_ids_for_training.append(movie_id)\n",
    "        \n",
    "        return set(movie_ids_for_training)\n",
    "\n",
    "\n",
    "    def _makeNeg(self):\n",
    "\n",
    "        user_negative_samples = dict()\n",
    "\n",
    "        for user in self.set_users:\n",
    "            user_sequence_movies = self.df[self.df['userId']==user]['movieId'].tolist()\n",
    "            # 최조 조건을 만족하지 못한 것 포함, feedback있는 영화를 제외시킨다. \n",
    "            user_negative_movies = self.set_movies - set(user_sequence_movies)\n",
    "            user_negative_samples[user] = np.array(user_negative_movies)\n",
    "\n",
    "        return user_negative_samples\n",
    "\n",
    "\n",
    "    def _encode(self) -> Tuple[pd.DataFrame, LabelEncoder, LabelEncoder]:\n",
    "        userId_label_encoder = LabelEncoder()\n",
    "        movieId_label_encoder = LabelEncoder()\n",
    "\n",
    "        self.df['userId'] = userId_label_encoder.fit_transform(self.df['userId'].values)\n",
    "        self.df['movieId'] = movieId_label_encoder.fit_transform(self.df['movieId'].values)\n",
    "\n",
    "        # encoder.inverse_transform() 으로 decode\n",
    "        return userId_label_encoder, movieId_label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFDataSet(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # nn.Embedding은 input 타입이 정수이어야 한다.\n",
    "        user = torch.tensor(self.df.iloc[idx]['userId']).to(torch.int64)\n",
    "        item = torch.tensor(self.df.iloc[idx]['movieId']).to(torch.int64)\n",
    "        rating = torch.tensor(self.df.iloc[idx]['rating']).float()\n",
    "\n",
    "        return user, item, rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, latent_dim, global_mean):\n",
    "        super(MF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, latent_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, latent_dim)\n",
    "        self.user_bias_embedding = nn.Embedding(num_users, 1)\n",
    "        self.item_bias_embedding = nn.Embedding(num_items, 1)\n",
    "        self.global_mean = global_mean\n",
    "\n",
    "        self._init_weights()   \n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
    "        self.user_bias_embedding.weight.data.fill_(1)\n",
    "        self.item_bias_embedding.weight.data.fill_(1)\n",
    "    \n",
    "    def forward(self, indices_user, indices_item):\n",
    "        user_latent = self.user_embedding(indices_user)\n",
    "        item_latent = self.item_embedding(indices_item)\n",
    "\n",
    "        product = torch.sum(user_latent * item_latent, axis=1)\n",
    "\n",
    "        user_bias = self.user_bias_embedding(indices_user).squeeze()\n",
    "        item_bias = self.item_bias_embedding(indices_user).squeeze()\n",
    "\n",
    "\n",
    "        output = self.global_mean + user_bias + item_bias + product\n",
    "\n",
    "        # loss 계산할 때 float이어야 한다.\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRLoss(nn.Modlue):\n",
    "    def __init__(self):\n",
    "        super(BPRLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, positive, negative):\n",
    "        distances = positive - negative\n",
    "        loss = - torch.sum(torch.log(nn.Sigmoid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choiceRandomItem(df, selected_item, set_items):\n",
    "    device = selected_item.get_device()\n",
    "    selected_item = selected_item.detach().cpu().numpy()\n",
    "    choice_item = random.choice(set_items)\n",
    "    \n",
    "    while selected_item == choice_item:\n",
    "        choice_item = random.choice(set_items)\n",
    "    \n",
    "    return torch.Tensor(choice_item, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, criterion, optimizer, epochs, device, df=None, set_items=None):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    loss_list = list()\n",
    "    size = len(data_loader)\n",
    "\n",
    "    # 훈련 시간 측정\n",
    "    epoch_start = torch.cuda.Event(enable_timing=True)\n",
    "    epoch_end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        # 시작 시간 기록\n",
    "        epoch_start.record()\n",
    "\n",
    "        for user, item, rating in data_loader:\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            rating = rating.to(device)\n",
    "\n",
    "            output = model(user, item)\n",
    "\n",
    "            # another_item, anoter_rating = choiceRandomItem(df, item, set_items)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(output, rating)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        epoch_end.record()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        avg_loss = epoch_loss / size\n",
    "        loss_list.append(avg_loss)\n",
    "\n",
    "        print(\n",
    "            f'Epoch[{epoch+1}/{epochs}]\\ttrain_loss: {avg_loss:.4f}' +\n",
    "            f'\\t훈련시간: {epoch_start.elapsed_time(epoch_end)/1000:.2f} sec'\n",
    "        )\n",
    "\n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "setSeed(42)\n",
    "data = DataInfo(dir_file_path.path_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = {\n",
    "    'latent_dim': 20,\n",
    "    'learning_rate': 0.01,\n",
    "    'epochs': 10,\n",
    "    'batch_size': 128,\n",
    "}\n",
    "\n",
    "hyper = Box(hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'gpu_idx': 0,\n",
    "    'criterion': 'adam',\n",
    "}\n",
    "\n",
    "config = Box(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_mean = data.df['rating'].mean()\n",
    "model = MF(data.num_users, data.num_movies, hyper.latent_dim, global_mean)\n",
    "device = torch.device(f\"cuda:{config.gpu_idx}\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset = MFDataSet(df=data.df)\n",
    "data_loader = DataLoader(dataset, batch_size=hyper.batch_size, shuffle=True)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hyper.learning_rate, amsgrad=True, weight_decay=0.2)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/15]\ttrain_loss: 1.2940\t훈련시간: 39.48 sec\n",
      "Epoch[2/15]\ttrain_loss: 0.6157\t훈련시간: 39.11 sec\n",
      "Epoch[3/15]\ttrain_loss: 0.4364\t훈련시간: 39.41 sec\n",
      "Epoch[4/15]\ttrain_loss: 0.3619\t훈련시간: 39.11 sec\n",
      "Epoch[5/15]\ttrain_loss: 0.3205\t훈련시간: 39.01 sec\n",
      "Epoch[6/15]\ttrain_loss: 0.2972\t훈련시간: 38.93 sec\n",
      "Epoch[7/15]\ttrain_loss: 0.2791\t훈련시간: 38.32 sec\n",
      "Epoch[8/15]\ttrain_loss: 0.2688\t훈련시간: 37.60 sec\n",
      "Epoch[9/15]\ttrain_loss: 0.2585\t훈련시간: 38.37 sec\n",
      "Epoch[10/15]\ttrain_loss: 0.2516\t훈련시간: 38.20 sec\n",
      "Epoch[11/15]\ttrain_loss: 0.2451\t훈련시간: 37.81 sec\n",
      "Epoch[12/15]\ttrain_loss: 0.2403\t훈련시간: 37.77 sec\n",
      "Epoch[13/15]\ttrain_loss: 0.2366\t훈련시간: 38.40 sec\n",
      "Epoch[14/15]\ttrain_loss: 0.2324\t훈련시간: 37.59 sec\n",
      "Epoch[15/15]\ttrain_loss: 0.2306\t훈련시간: 37.69 sec\n"
     ]
    }
   ],
   "source": [
    "loss_list = train(model, data_loader, criterion, optimizer, hyper.epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = [i for i in range(1, hyper.epochs+1)]\n",
    "y = loss_list\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictedFullMatrix(user_embedding, item_embedding, global_mean, user_bias, item_bias):\n",
    "\n",
    "    num_users = user_embedding.shape[0]\n",
    "    num_items = item_embedding.shape[0]\n",
    "\n",
    "    matrix_multiplied_with_bias = np.ones(shape=(num_users, num_items))\n",
    "\n",
    "    if global_mean is None:\n",
    "        return user_embedding @ item_embedding.T\n",
    "    else:\n",
    "        values = [\n",
    "            user_embedding @ item_embedding.T,\n",
    "            matrix_multiplied_with_bias * item_bias,\n",
    "            np.array([user_bias]).T * matrix_multiplied_with_bias,\n",
    "            matrix_multiplied_with_bias * global_mean\n",
    "        ]\n",
    "        return sum(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9714</th>\n",
       "      <th>9715</th>\n",
       "      <th>9716</th>\n",
       "      <th>9717</th>\n",
       "      <th>9718</th>\n",
       "      <th>9719</th>\n",
       "      <th>9720</th>\n",
       "      <th>9721</th>\n",
       "      <th>9722</th>\n",
       "      <th>9723</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.541255</td>\n",
       "      <td>3.268673</td>\n",
       "      <td>3.733323</td>\n",
       "      <td>2.758586</td>\n",
       "      <td>3.941763</td>\n",
       "      <td>4.223502</td>\n",
       "      <td>2.335995</td>\n",
       "      <td>3.593154</td>\n",
       "      <td>3.332051</td>\n",
       "      <td>3.277963</td>\n",
       "      <td>...</td>\n",
       "      <td>4.656973</td>\n",
       "      <td>4.825168</td>\n",
       "      <td>4.955891</td>\n",
       "      <td>5.066469</td>\n",
       "      <td>4.850731</td>\n",
       "      <td>4.785079</td>\n",
       "      <td>5.007418</td>\n",
       "      <td>5.105509</td>\n",
       "      <td>4.825781</td>\n",
       "      <td>4.610891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.640587</td>\n",
       "      <td>4.647205</td>\n",
       "      <td>3.879587</td>\n",
       "      <td>3.638487</td>\n",
       "      <td>4.994726</td>\n",
       "      <td>3.310178</td>\n",
       "      <td>4.169986</td>\n",
       "      <td>4.488691</td>\n",
       "      <td>4.580897</td>\n",
       "      <td>3.556931</td>\n",
       "      <td>...</td>\n",
       "      <td>4.909061</td>\n",
       "      <td>4.613625</td>\n",
       "      <td>4.466398</td>\n",
       "      <td>4.677858</td>\n",
       "      <td>5.426601</td>\n",
       "      <td>4.431877</td>\n",
       "      <td>5.140741</td>\n",
       "      <td>5.152614</td>\n",
       "      <td>5.094354</td>\n",
       "      <td>4.512695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.476894</td>\n",
       "      <td>4.305407</td>\n",
       "      <td>1.771808</td>\n",
       "      <td>3.134586</td>\n",
       "      <td>2.764103</td>\n",
       "      <td>3.405545</td>\n",
       "      <td>4.854968</td>\n",
       "      <td>2.203632</td>\n",
       "      <td>1.950592</td>\n",
       "      <td>3.626805</td>\n",
       "      <td>...</td>\n",
       "      <td>4.161703</td>\n",
       "      <td>3.654097</td>\n",
       "      <td>3.733479</td>\n",
       "      <td>3.904288</td>\n",
       "      <td>3.920938</td>\n",
       "      <td>3.688823</td>\n",
       "      <td>3.796728</td>\n",
       "      <td>4.058354</td>\n",
       "      <td>4.193303</td>\n",
       "      <td>3.695082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.623701</td>\n",
       "      <td>3.505435</td>\n",
       "      <td>2.072833</td>\n",
       "      <td>1.739616</td>\n",
       "      <td>2.410070</td>\n",
       "      <td>3.416078</td>\n",
       "      <td>1.258137</td>\n",
       "      <td>2.986890</td>\n",
       "      <td>2.262819</td>\n",
       "      <td>1.647753</td>\n",
       "      <td>...</td>\n",
       "      <td>4.232395</td>\n",
       "      <td>3.802185</td>\n",
       "      <td>4.615644</td>\n",
       "      <td>5.218127</td>\n",
       "      <td>4.896604</td>\n",
       "      <td>3.978344</td>\n",
       "      <td>4.655009</td>\n",
       "      <td>4.403668</td>\n",
       "      <td>4.531268</td>\n",
       "      <td>4.331128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.203315</td>\n",
       "      <td>3.992628</td>\n",
       "      <td>2.378826</td>\n",
       "      <td>2.851542</td>\n",
       "      <td>5.069207</td>\n",
       "      <td>3.517500</td>\n",
       "      <td>3.849735</td>\n",
       "      <td>2.489796</td>\n",
       "      <td>3.376115</td>\n",
       "      <td>2.657606</td>\n",
       "      <td>...</td>\n",
       "      <td>4.083202</td>\n",
       "      <td>5.040140</td>\n",
       "      <td>4.707536</td>\n",
       "      <td>3.611289</td>\n",
       "      <td>3.031184</td>\n",
       "      <td>4.671480</td>\n",
       "      <td>4.417003</td>\n",
       "      <td>4.936543</td>\n",
       "      <td>4.457183</td>\n",
       "      <td>4.147113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>3.961263</td>\n",
       "      <td>3.034577</td>\n",
       "      <td>2.623880</td>\n",
       "      <td>2.927360</td>\n",
       "      <td>3.026858</td>\n",
       "      <td>4.224631</td>\n",
       "      <td>3.349872</td>\n",
       "      <td>2.653618</td>\n",
       "      <td>2.371942</td>\n",
       "      <td>2.865330</td>\n",
       "      <td>...</td>\n",
       "      <td>4.560386</td>\n",
       "      <td>4.574605</td>\n",
       "      <td>4.787482</td>\n",
       "      <td>4.613914</td>\n",
       "      <td>4.615569</td>\n",
       "      <td>4.539136</td>\n",
       "      <td>4.906668</td>\n",
       "      <td>4.296246</td>\n",
       "      <td>4.560696</td>\n",
       "      <td>4.663172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>4.347180</td>\n",
       "      <td>2.891072</td>\n",
       "      <td>3.779262</td>\n",
       "      <td>4.564283</td>\n",
       "      <td>3.618605</td>\n",
       "      <td>4.584004</td>\n",
       "      <td>2.677955</td>\n",
       "      <td>1.230883</td>\n",
       "      <td>3.250719</td>\n",
       "      <td>2.426607</td>\n",
       "      <td>...</td>\n",
       "      <td>3.911911</td>\n",
       "      <td>5.113673</td>\n",
       "      <td>3.966566</td>\n",
       "      <td>3.993947</td>\n",
       "      <td>3.538245</td>\n",
       "      <td>4.903988</td>\n",
       "      <td>4.060249</td>\n",
       "      <td>4.903824</td>\n",
       "      <td>3.978189</td>\n",
       "      <td>3.938796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>3.381187</td>\n",
       "      <td>2.863467</td>\n",
       "      <td>1.338654</td>\n",
       "      <td>3.024237</td>\n",
       "      <td>1.889636</td>\n",
       "      <td>4.286381</td>\n",
       "      <td>3.259626</td>\n",
       "      <td>3.495695</td>\n",
       "      <td>3.359475</td>\n",
       "      <td>3.564735</td>\n",
       "      <td>...</td>\n",
       "      <td>5.073003</td>\n",
       "      <td>4.624624</td>\n",
       "      <td>4.566243</td>\n",
       "      <td>4.865709</td>\n",
       "      <td>4.459692</td>\n",
       "      <td>5.060599</td>\n",
       "      <td>4.232721</td>\n",
       "      <td>4.516377</td>\n",
       "      <td>4.637625</td>\n",
       "      <td>4.604384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>3.521215</td>\n",
       "      <td>3.749140</td>\n",
       "      <td>1.901281</td>\n",
       "      <td>2.743341</td>\n",
       "      <td>3.294143</td>\n",
       "      <td>3.778263</td>\n",
       "      <td>3.153403</td>\n",
       "      <td>2.850193</td>\n",
       "      <td>3.339333</td>\n",
       "      <td>3.582821</td>\n",
       "      <td>...</td>\n",
       "      <td>3.793907</td>\n",
       "      <td>4.730321</td>\n",
       "      <td>4.113061</td>\n",
       "      <td>4.203710</td>\n",
       "      <td>4.093840</td>\n",
       "      <td>4.143713</td>\n",
       "      <td>4.333779</td>\n",
       "      <td>4.218453</td>\n",
       "      <td>3.913007</td>\n",
       "      <td>4.369889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>4.399545</td>\n",
       "      <td>3.350646</td>\n",
       "      <td>2.815694</td>\n",
       "      <td>2.755641</td>\n",
       "      <td>2.123710</td>\n",
       "      <td>4.707243</td>\n",
       "      <td>2.753398</td>\n",
       "      <td>3.120028</td>\n",
       "      <td>2.738050</td>\n",
       "      <td>3.791275</td>\n",
       "      <td>...</td>\n",
       "      <td>4.759598</td>\n",
       "      <td>4.509622</td>\n",
       "      <td>4.830383</td>\n",
       "      <td>4.833440</td>\n",
       "      <td>4.576164</td>\n",
       "      <td>4.765506</td>\n",
       "      <td>4.607399</td>\n",
       "      <td>4.294912</td>\n",
       "      <td>4.510527</td>\n",
       "      <td>4.826280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 9724 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "0    4.541255  3.268673  3.733323  2.758586  3.941763  4.223502  2.335995   \n",
       "1    4.640587  4.647205  3.879587  3.638487  4.994726  3.310178  4.169986   \n",
       "2    4.476894  4.305407  1.771808  3.134586  2.764103  3.405545  4.854968   \n",
       "3    4.623701  3.505435  2.072833  1.739616  2.410070  3.416078  1.258137   \n",
       "4    4.203315  3.992628  2.378826  2.851542  5.069207  3.517500  3.849735   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "605  3.961263  3.034577  2.623880  2.927360  3.026858  4.224631  3.349872   \n",
       "606  4.347180  2.891072  3.779262  4.564283  3.618605  4.584004  2.677955   \n",
       "607  3.381187  2.863467  1.338654  3.024237  1.889636  4.286381  3.259626   \n",
       "608  3.521215  3.749140  1.901281  2.743341  3.294143  3.778263  3.153403   \n",
       "609  4.399545  3.350646  2.815694  2.755641  2.123710  4.707243  2.753398   \n",
       "\n",
       "         7         8         9     ...      9714      9715      9716  \\\n",
       "0    3.593154  3.332051  3.277963  ...  4.656973  4.825168  4.955891   \n",
       "1    4.488691  4.580897  3.556931  ...  4.909061  4.613625  4.466398   \n",
       "2    2.203632  1.950592  3.626805  ...  4.161703  3.654097  3.733479   \n",
       "3    2.986890  2.262819  1.647753  ...  4.232395  3.802185  4.615644   \n",
       "4    2.489796  3.376115  2.657606  ...  4.083202  5.040140  4.707536   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "605  2.653618  2.371942  2.865330  ...  4.560386  4.574605  4.787482   \n",
       "606  1.230883  3.250719  2.426607  ...  3.911911  5.113673  3.966566   \n",
       "607  3.495695  3.359475  3.564735  ...  5.073003  4.624624  4.566243   \n",
       "608  2.850193  3.339333  3.582821  ...  3.793907  4.730321  4.113061   \n",
       "609  3.120028  2.738050  3.791275  ...  4.759598  4.509622  4.830383   \n",
       "\n",
       "         9717      9718      9719      9720      9721      9722      9723  \n",
       "0    5.066469  4.850731  4.785079  5.007418  5.105509  4.825781  4.610891  \n",
       "1    4.677858  5.426601  4.431877  5.140741  5.152614  5.094354  4.512695  \n",
       "2    3.904288  3.920938  3.688823  3.796728  4.058354  4.193303  3.695082  \n",
       "3    5.218127  4.896604  3.978344  4.655009  4.403668  4.531268  4.331128  \n",
       "4    3.611289  3.031184  4.671480  4.417003  4.936543  4.457183  4.147113  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "605  4.613914  4.615569  4.539136  4.906668  4.296246  4.560696  4.663172  \n",
       "606  3.993947  3.538245  4.903988  4.060249  4.903824  3.978189  3.938796  \n",
       "607  4.865709  4.459692  5.060599  4.232721  4.516377  4.637625  4.604384  \n",
       "608  4.203710  4.093840  4.143713  4.333779  4.218453  3.913007  4.369889  \n",
       "609  4.833440  4.576164  4.765506  4.607399  4.294912  4.510527  4.826280  \n",
       "\n",
       "[610 rows x 9724 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding = model.user_embedding.weight.data.detach().cpu().numpy()\n",
    "item_embedding = model.item_embedding.weight.data.detach().cpu().numpy()\n",
    "user_biase_embedding = np.squeeze(model.user_bias_embedding.weight.data.detach().cpu().numpy())\n",
    "item_biase_embedding = np.squeeze(model.item_bias_embedding.weight.data.detach().cpu().numpy())\n",
    "\n",
    "predict = pd.DataFrame(\n",
    "    getPredictedFullMatrix(user_embedding, item_embedding, global_mean, user_biase_embedding, item_biase_embedding),\n",
    "    columns = data.set_movies,\n",
    "    index = data.set_users\n",
    ")\n",
    "\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
