{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from box import Box\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import copy\n",
    "\n",
    "from typing import Tuple\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setSeed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_base = os.path.join(os.path.join('/opt','ml','paper','RecSys'))\n",
    "dir_data = os.path.join(dir_base, 'Data', 'ml-latest-small')\n",
    "path_rating = os.path.join(dir_data, 'ratings.csv')\n",
    "dir_file_path = {\n",
    "    'dir_base': dir_base,\n",
    "    'dir_data': dir_data,\n",
    "    'path_rating': path_rating,\n",
    "}\n",
    "\n",
    "dir_file_path = Box(dir_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataInfo():\n",
    "    def __init__(self, file_path: str) -> None:\n",
    "        self.df = pd.read_csv(file_path)\n",
    "        self.user_encoder, self.movie_encoder = self._encode()\n",
    "\n",
    "        self.set_users = set(self.df['userId'].unique())\n",
    "        self.num_users = len(self.set_users)\n",
    "        self.set_movies = set(self.df['movieId'].unique())\n",
    "        self.num_movies = len(self.set_movies)\n",
    "\n",
    "    def _encode(self) -> Tuple[pd.DataFrame, LabelEncoder, LabelEncoder]:\n",
    "        userId_label_encoder = LabelEncoder()\n",
    "        movieId_label_encoder = LabelEncoder()\n",
    "\n",
    "        self.df['userId'] = userId_label_encoder.fit_transform(self.df['userId'].values)\n",
    "        self.df['movieId'] = movieId_label_encoder.fit_transform(self.df['movieId'].values)\n",
    "\n",
    "        # encoder.inverse_transform() 으로 decode\n",
    "        return userId_label_encoder, movieId_label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFDataSet(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # nn.Embedding은 input 타입이 정수이어야 한다.\n",
    "        user = torch.tensor(self.df.iloc[idx]['userId']).to(torch.int64)\n",
    "        item = torch.tensor(self.df.iloc[idx]['movieId']).to(torch.int64)\n",
    "        rating = torch.tensor(self.df.iloc[idx]['rating']).float()\n",
    "\n",
    "        return user, item, rating, torch.Tensor(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRDataSet(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.df = data.df\n",
    "        self.items = data.set_movies\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        user = torch.tensor(self.df.iloc[idx]['userId']).to(torch.int64)\n",
    "        item = torch.tensor(self.df.iloc[idx]['movieId']).to(torch.int64) # self.df.iloc[idx]['movieId']\n",
    "        rating = torch.tensor(self.df.iloc[idx]['rating']).float()\n",
    "\n",
    "        neg_item = self._choiceRandomItem(user, item, rating)\n",
    "        neg_item = torch.tensor(neg_item).to(torch.int64)\n",
    "\n",
    "        return user, item, rating, neg_item\n",
    "    \n",
    "    def _choiceRandomItem(self, user, item, rating):\n",
    "        user = int(user.detach().cpu().numpy())\n",
    "        item = int(item.detach().cpu().numpy())\n",
    "        rating = float(rating.detach().cpu().numpy())\n",
    "        \n",
    "        candi_item = list(self.items - set([item]))\n",
    "        choice_item = int(random.sample(candi_item, 1)[0])\n",
    "\n",
    "        choice_rating = self.df[(self.df['userId'] == user) & (self.df['movieId'] == choice_item)]['rating']\n",
    "        \n",
    "        while (not choice_rating.empty) and (rating <= choice_rating.values):\n",
    "            choice_item = int(random.sample(candi_item, 1)[0])\n",
    "            choice_rating = self.df[(self.df['userId'] == user) & (self.df['movieId'] == choice_item)]['rating']\n",
    "        \n",
    "        return choice_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, latent_dim, global_mean):\n",
    "        super(MF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, latent_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, latent_dim)\n",
    "        self.user_bias_embedding = nn.Embedding(num_users, 1)\n",
    "        self.item_bias_embedding = nn.Embedding(num_items, 1)\n",
    "        self.global_mean = global_mean\n",
    "\n",
    "        self._init_weights()   \n",
    "\n",
    "    def _init_weights(self):\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.item_embedding.weight)\n",
    "        self.user_bias_embedding.weight.data.fill_(1)\n",
    "        self.item_bias_embedding.weight.data.fill_(1)\n",
    "    \n",
    "    def forward(self, indices_user, indices_item):\n",
    "        user_latent = self.user_embedding(indices_user)\n",
    "        item_latent = self.item_embedding(indices_item)\n",
    "\n",
    "        product = torch.sum(user_latent * item_latent, axis=1)\n",
    "\n",
    "        user_bias = self.user_bias_embedding(indices_user).squeeze()\n",
    "        item_bias = self.item_bias_embedding(indices_item).squeeze()\n",
    "\n",
    "\n",
    "        output = self.global_mean + user_bias + item_bias + product\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BPRLoss, self).__init__()\n",
    "        self.logsigmoid = nn.LogSigmoid()\n",
    "    \n",
    "    def forward(self, positive, negative):\n",
    "        distances = positive - negative\n",
    "        loss = -torch.mean(self.logsigmoid(distances))\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data_loader, criterion, optimizer, epochs, device):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    \n",
    "    loss_list = list()\n",
    "    size = len(data_loader)\n",
    "\n",
    "    # 훈련 시간 측정\n",
    "    epoch_start = torch.cuda.Event(enable_timing=True)\n",
    "    epoch_end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "\n",
    "        # 시작 시간 기록\n",
    "        epoch_start.record()\n",
    "\n",
    "        for user, item, rating, neg_item in tqdm(data_loader):\n",
    "            user = user.to(device)\n",
    "            item = item.to(device)\n",
    "            rating = rating.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            if neg_item.nelement() == 0:\n",
    "                # MF\n",
    "                pred = model(user, item)\n",
    "                loss = criterion(pred, rating)\n",
    "            else:\n",
    "                # BPR\n",
    "                neg_item = neg_item.to(device)\n",
    "                pos = model(user, item)\n",
    "                neg = model(user, neg_item)\n",
    "                loss = criterion(pos, neg)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        epoch_end.record()\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        avg_loss = epoch_loss / size\n",
    "        loss_list.append(avg_loss)\n",
    "\n",
    "        print(\n",
    "            f'Epoch[{epoch+1}/{epochs}]\\ttrain_loss: {avg_loss:.4f}' +\n",
    "            f'\\t훈련시간: {epoch_start.elapsed_time(epoch_end)/1000:.2f} sec'\n",
    "        )\n",
    "\n",
    "    return loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "setSeed(42)\n",
    "data = DataInfo(dir_file_path.path_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper = {\n",
    "    'latent_dim': 20,\n",
    "    'learning_rate': 0.01,\n",
    "    'epochs': 10,\n",
    "    'batch_size': 128,\n",
    "}\n",
    "\n",
    "hyper = Box(hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'gpu_idx': 0,\n",
    "    'criterion': 'adam',\n",
    "}\n",
    "\n",
    "config = Box(config)\n",
    "\n",
    "device = torch.device(f\"cuda:{config.gpu_idx}\" if torch.cuda.is_available() else \"cpu\")\n",
    "global_mean = data.df['rating'].mean()\n",
    "\n",
    "model_mf = MF(data.num_users, data.num_movies, hyper.latent_dim, global_mean)\n",
    "model_bpr = copy.deepcopy(model_mf) # BPR_MF(data.num_users, data.num_movies, hyper.latent_dim, global_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mf = MFDataSet(df=data.df)\n",
    "data_loader_mf = DataLoader(dataset_mf, batch_size=hyper.batch_size, shuffle=True)\n",
    "optimizer_mf = torch.optim.Adam(model_mf.parameters(), lr=hyper.learning_rate, amsgrad=True) # weight_decay = 0.2를 하면 학습이 안 된다....\n",
    "criterion_mf = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_bpr = BPRDataSet(data=data)\n",
    "data_loader_bpr = DataLoader(dataset_bpr, batch_size=hyper.batch_size, shuffle=True)\n",
    "optimizer_bpr = torch.optim.Adam(model_bpr.parameters(), lr=hyper.learning_rate, amsgrad=True) # weight_decay = 0.2를 하면 학습이 안 된다....\n",
    "criterion_bpr = BPRLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [00:39<00:00, 20.12it/s]\n",
      "  0%|          | 2/788 [00:00<00:46, 16.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/10]\ttrain_loss: 1.4922\t훈련시간: 39.17 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [00:38<00:00, 20.42it/s]\n",
      "  0%|          | 2/788 [00:00<00:56, 13.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[2/10]\ttrain_loss: 0.6622\t훈련시간: 38.59 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [00:38<00:00, 20.38it/s]\n",
      "  0%|          | 2/788 [00:00<00:49, 15.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3/10]\ttrain_loss: 0.4588\t훈련시간: 38.66 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [00:38<00:00, 20.33it/s]\n",
      "  0%|          | 1/788 [00:00<01:44,  7.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[4/10]\ttrain_loss: 0.3719\t훈련시간: 38.76 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [00:38<00:00, 20.27it/s]\n",
      "  0%|          | 1/788 [00:00<01:20,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5/10]\ttrain_loss: 0.3265\t훈련시간: 38.88 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [00:38<00:00, 20.31it/s]\n",
      "  0%|          | 2/788 [00:00<01:01, 12.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[6/10]\ttrain_loss: 0.2999\t훈련시간: 38.81 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [00:39<00:00, 20.14it/s]\n",
      "  0%|          | 2/788 [00:00<00:50, 15.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[7/10]\ttrain_loss: 0.2788\t훈련시간: 39.12 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [00:38<00:00, 20.41it/s]\n",
      "  0%|          | 2/788 [00:00<00:42, 18.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[8/10]\ttrain_loss: 0.2652\t훈련시간: 38.61 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [00:38<00:00, 20.33it/s]\n",
      "  0%|          | 2/788 [00:00<00:42, 18.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[9/10]\ttrain_loss: 0.2536\t훈련시간: 38.76 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [00:38<00:00, 20.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/10]\ttrain_loss: 0.2453\t훈련시간: 38.97 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mf_loss = train(model_mf, data_loader_mf, criterion_mf, optimizer_mf, hyper.epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [02:33<00:00,  5.12it/s]\n",
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1/10]\ttrain_loss: 0.4094\t훈련시간: 153.85 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [02:27<00:00,  5.34it/s]\n",
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[2/10]\ttrain_loss: 0.2382\t훈련시간: 147.49 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [02:23<00:00,  5.48it/s]\n",
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[3/10]\ttrain_loss: 0.1774\t훈련시간: 143.80 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [02:37<00:00,  5.01it/s]\n",
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[4/10]\ttrain_loss: 0.1488\t훈련시간: 157.36 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [02:32<00:00,  5.18it/s]\n",
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[5/10]\ttrain_loss: 0.1320\t훈련시간: 152.14 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [02:32<00:00,  5.16it/s]\n",
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[6/10]\ttrain_loss: 0.1204\t훈련시간: 152.60 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [02:31<00:00,  5.19it/s]\n",
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[7/10]\ttrain_loss: 0.1179\t훈련시간: 151.89 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [02:31<00:00,  5.22it/s]\n",
      "  0%|          | 0/788 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[8/10]\ttrain_loss: 0.1090\t훈련시간: 151.09 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [02:31<00:00,  5.22it/s]\n",
      "  0%|          | 1/788 [00:00<02:36,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[9/10]\ttrain_loss: 0.1074\t훈련시간: 151.04 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 788/788 [02:30<00:00,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[10/10]\ttrain_loss: 0.1025\t훈련시간: 150.58 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bpr_loss = train(model_bpr, data_loader_bpr, criterion_bpr, optimizer_bpr, hyper.epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "x = [i for i in range(1, hyper.epochs+1)]\n",
    "y1 = mf_loss\n",
    "y2 = bpr_loss\n",
    "\n",
    "ax.plot(x, y1)\n",
    "ax.plot(x, y2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictedFullMatrix(user_embedding, item_embedding, global_mean, user_bias, item_bias):\n",
    "\n",
    "    num_users = user_embedding.shape[0]\n",
    "    num_items = item_embedding.shape[0]\n",
    "\n",
    "    matrix_multiplied_with_bias = np.ones(shape=(num_users, num_items))\n",
    "\n",
    "    if global_mean is None:\n",
    "        return user_embedding @ item_embedding.T\n",
    "    else:\n",
    "        values = [\n",
    "            user_embedding @ item_embedding.T,\n",
    "            matrix_multiplied_with_bias * item_bias,\n",
    "            np.array([user_bias]).T * matrix_multiplied_with_bias,\n",
    "            matrix_multiplied_with_bias * global_mean\n",
    "        ]\n",
    "        return sum(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9714</th>\n",
       "      <th>9715</th>\n",
       "      <th>9716</th>\n",
       "      <th>9717</th>\n",
       "      <th>9718</th>\n",
       "      <th>9719</th>\n",
       "      <th>9720</th>\n",
       "      <th>9721</th>\n",
       "      <th>9722</th>\n",
       "      <th>9723</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.689483</td>\n",
       "      <td>3.575229</td>\n",
       "      <td>4.513450</td>\n",
       "      <td>2.998103</td>\n",
       "      <td>4.875282</td>\n",
       "      <td>4.408030</td>\n",
       "      <td>2.449848</td>\n",
       "      <td>3.646189</td>\n",
       "      <td>3.034403</td>\n",
       "      <td>3.452409</td>\n",
       "      <td>...</td>\n",
       "      <td>4.441032</td>\n",
       "      <td>4.581538</td>\n",
       "      <td>4.178109</td>\n",
       "      <td>4.403262</td>\n",
       "      <td>4.340701</td>\n",
       "      <td>4.246437</td>\n",
       "      <td>5.048597</td>\n",
       "      <td>4.862494</td>\n",
       "      <td>5.281557</td>\n",
       "      <td>3.773314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.627876</td>\n",
       "      <td>4.336096</td>\n",
       "      <td>4.342385</td>\n",
       "      <td>3.473666</td>\n",
       "      <td>4.691597</td>\n",
       "      <td>3.175901</td>\n",
       "      <td>4.085804</td>\n",
       "      <td>4.612026</td>\n",
       "      <td>4.382684</td>\n",
       "      <td>3.811994</td>\n",
       "      <td>...</td>\n",
       "      <td>4.595633</td>\n",
       "      <td>5.035953</td>\n",
       "      <td>4.224408</td>\n",
       "      <td>4.058438</td>\n",
       "      <td>4.476663</td>\n",
       "      <td>3.982890</td>\n",
       "      <td>4.559601</td>\n",
       "      <td>4.743816</td>\n",
       "      <td>5.385302</td>\n",
       "      <td>4.185512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.016190</td>\n",
       "      <td>3.149055</td>\n",
       "      <td>0.344930</td>\n",
       "      <td>1.289803</td>\n",
       "      <td>1.378903</td>\n",
       "      <td>3.378115</td>\n",
       "      <td>2.819276</td>\n",
       "      <td>-0.907448</td>\n",
       "      <td>0.818480</td>\n",
       "      <td>2.806827</td>\n",
       "      <td>...</td>\n",
       "      <td>4.332988</td>\n",
       "      <td>4.388939</td>\n",
       "      <td>3.482871</td>\n",
       "      <td>2.708053</td>\n",
       "      <td>2.889636</td>\n",
       "      <td>2.997909</td>\n",
       "      <td>3.370863</td>\n",
       "      <td>4.155338</td>\n",
       "      <td>4.781958</td>\n",
       "      <td>2.512744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.251019</td>\n",
       "      <td>3.588310</td>\n",
       "      <td>3.050722</td>\n",
       "      <td>1.836939</td>\n",
       "      <td>2.652235</td>\n",
       "      <td>3.600753</td>\n",
       "      <td>2.101373</td>\n",
       "      <td>3.145765</td>\n",
       "      <td>1.265155</td>\n",
       "      <td>2.292165</td>\n",
       "      <td>...</td>\n",
       "      <td>2.735801</td>\n",
       "      <td>3.223545</td>\n",
       "      <td>3.589657</td>\n",
       "      <td>3.951657</td>\n",
       "      <td>3.202153</td>\n",
       "      <td>3.273953</td>\n",
       "      <td>4.283572</td>\n",
       "      <td>3.716254</td>\n",
       "      <td>3.534183</td>\n",
       "      <td>2.859826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.268290</td>\n",
       "      <td>3.908867</td>\n",
       "      <td>1.759764</td>\n",
       "      <td>1.582589</td>\n",
       "      <td>3.890734</td>\n",
       "      <td>2.876808</td>\n",
       "      <td>3.401522</td>\n",
       "      <td>2.327524</td>\n",
       "      <td>3.514471</td>\n",
       "      <td>2.497793</td>\n",
       "      <td>...</td>\n",
       "      <td>5.675385</td>\n",
       "      <td>5.768949</td>\n",
       "      <td>5.118394</td>\n",
       "      <td>3.787526</td>\n",
       "      <td>3.436669</td>\n",
       "      <td>3.842393</td>\n",
       "      <td>3.748997</td>\n",
       "      <td>5.043417</td>\n",
       "      <td>4.842300</td>\n",
       "      <td>2.907836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>3.839025</td>\n",
       "      <td>3.123975</td>\n",
       "      <td>3.432623</td>\n",
       "      <td>2.622404</td>\n",
       "      <td>2.787986</td>\n",
       "      <td>4.015721</td>\n",
       "      <td>2.629791</td>\n",
       "      <td>3.288613</td>\n",
       "      <td>2.023435</td>\n",
       "      <td>3.004912</td>\n",
       "      <td>...</td>\n",
       "      <td>3.557389</td>\n",
       "      <td>3.485544</td>\n",
       "      <td>3.918252</td>\n",
       "      <td>4.005725</td>\n",
       "      <td>3.395095</td>\n",
       "      <td>3.808558</td>\n",
       "      <td>3.656519</td>\n",
       "      <td>3.478156</td>\n",
       "      <td>3.396420</td>\n",
       "      <td>3.333128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>3.628231</td>\n",
       "      <td>4.098181</td>\n",
       "      <td>4.330986</td>\n",
       "      <td>4.282894</td>\n",
       "      <td>4.091636</td>\n",
       "      <td>3.899693</td>\n",
       "      <td>3.098940</td>\n",
       "      <td>3.335688</td>\n",
       "      <td>3.396100</td>\n",
       "      <td>3.509620</td>\n",
       "      <td>...</td>\n",
       "      <td>4.572393</td>\n",
       "      <td>4.521976</td>\n",
       "      <td>4.419273</td>\n",
       "      <td>3.394211</td>\n",
       "      <td>3.896777</td>\n",
       "      <td>3.846544</td>\n",
       "      <td>4.755417</td>\n",
       "      <td>5.038062</td>\n",
       "      <td>3.525161</td>\n",
       "      <td>3.724340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>2.674081</td>\n",
       "      <td>2.328694</td>\n",
       "      <td>1.995826</td>\n",
       "      <td>2.929720</td>\n",
       "      <td>1.676676</td>\n",
       "      <td>4.218599</td>\n",
       "      <td>2.973762</td>\n",
       "      <td>3.498707</td>\n",
       "      <td>3.334999</td>\n",
       "      <td>3.556590</td>\n",
       "      <td>...</td>\n",
       "      <td>4.227307</td>\n",
       "      <td>3.785642</td>\n",
       "      <td>4.098510</td>\n",
       "      <td>3.943209</td>\n",
       "      <td>3.795511</td>\n",
       "      <td>3.975129</td>\n",
       "      <td>3.879058</td>\n",
       "      <td>3.661006</td>\n",
       "      <td>3.204340</td>\n",
       "      <td>3.880761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>3.133214</td>\n",
       "      <td>2.692760</td>\n",
       "      <td>2.619822</td>\n",
       "      <td>2.706076</td>\n",
       "      <td>2.615097</td>\n",
       "      <td>4.541626</td>\n",
       "      <td>2.855276</td>\n",
       "      <td>1.796524</td>\n",
       "      <td>2.129480</td>\n",
       "      <td>3.706346</td>\n",
       "      <td>...</td>\n",
       "      <td>4.279027</td>\n",
       "      <td>4.063949</td>\n",
       "      <td>4.083903</td>\n",
       "      <td>3.489988</td>\n",
       "      <td>3.318610</td>\n",
       "      <td>3.519682</td>\n",
       "      <td>3.984520</td>\n",
       "      <td>3.977219</td>\n",
       "      <td>4.084922</td>\n",
       "      <td>3.205494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>4.806889</td>\n",
       "      <td>3.546530</td>\n",
       "      <td>3.645798</td>\n",
       "      <td>3.351135</td>\n",
       "      <td>2.370061</td>\n",
       "      <td>4.657864</td>\n",
       "      <td>1.908017</td>\n",
       "      <td>3.567549</td>\n",
       "      <td>3.183811</td>\n",
       "      <td>3.919184</td>\n",
       "      <td>...</td>\n",
       "      <td>4.146792</td>\n",
       "      <td>3.464052</td>\n",
       "      <td>4.123124</td>\n",
       "      <td>4.210889</td>\n",
       "      <td>3.943505</td>\n",
       "      <td>4.174804</td>\n",
       "      <td>4.003542</td>\n",
       "      <td>3.799571</td>\n",
       "      <td>4.016688</td>\n",
       "      <td>4.386631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>610 rows × 9724 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6     \\\n",
       "0    4.689483  3.575229  4.513450  2.998103  4.875282  4.408030  2.449848   \n",
       "1    4.627876  4.336096  4.342385  3.473666  4.691597  3.175901  4.085804   \n",
       "2    3.016190  3.149055  0.344930  1.289803  1.378903  3.378115  2.819276   \n",
       "3    3.251019  3.588310  3.050722  1.836939  2.652235  3.600753  2.101373   \n",
       "4    4.268290  3.908867  1.759764  1.582589  3.890734  2.876808  3.401522   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "605  3.839025  3.123975  3.432623  2.622404  2.787986  4.015721  2.629791   \n",
       "606  3.628231  4.098181  4.330986  4.282894  4.091636  3.899693  3.098940   \n",
       "607  2.674081  2.328694  1.995826  2.929720  1.676676  4.218599  2.973762   \n",
       "608  3.133214  2.692760  2.619822  2.706076  2.615097  4.541626  2.855276   \n",
       "609  4.806889  3.546530  3.645798  3.351135  2.370061  4.657864  1.908017   \n",
       "\n",
       "         7         8         9     ...      9714      9715      9716  \\\n",
       "0    3.646189  3.034403  3.452409  ...  4.441032  4.581538  4.178109   \n",
       "1    4.612026  4.382684  3.811994  ...  4.595633  5.035953  4.224408   \n",
       "2   -0.907448  0.818480  2.806827  ...  4.332988  4.388939  3.482871   \n",
       "3    3.145765  1.265155  2.292165  ...  2.735801  3.223545  3.589657   \n",
       "4    2.327524  3.514471  2.497793  ...  5.675385  5.768949  5.118394   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "605  3.288613  2.023435  3.004912  ...  3.557389  3.485544  3.918252   \n",
       "606  3.335688  3.396100  3.509620  ...  4.572393  4.521976  4.419273   \n",
       "607  3.498707  3.334999  3.556590  ...  4.227307  3.785642  4.098510   \n",
       "608  1.796524  2.129480  3.706346  ...  4.279027  4.063949  4.083903   \n",
       "609  3.567549  3.183811  3.919184  ...  4.146792  3.464052  4.123124   \n",
       "\n",
       "         9717      9718      9719      9720      9721      9722      9723  \n",
       "0    4.403262  4.340701  4.246437  5.048597  4.862494  5.281557  3.773314  \n",
       "1    4.058438  4.476663  3.982890  4.559601  4.743816  5.385302  4.185512  \n",
       "2    2.708053  2.889636  2.997909  3.370863  4.155338  4.781958  2.512744  \n",
       "3    3.951657  3.202153  3.273953  4.283572  3.716254  3.534183  2.859826  \n",
       "4    3.787526  3.436669  3.842393  3.748997  5.043417  4.842300  2.907836  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "605  4.005725  3.395095  3.808558  3.656519  3.478156  3.396420  3.333128  \n",
       "606  3.394211  3.896777  3.846544  4.755417  5.038062  3.525161  3.724340  \n",
       "607  3.943209  3.795511  3.975129  3.879058  3.661006  3.204340  3.880761  \n",
       "608  3.489988  3.318610  3.519682  3.984520  3.977219  4.084922  3.205494  \n",
       "609  4.210889  3.943505  4.174804  4.003542  3.799571  4.016688  4.386631  \n",
       "\n",
       "[610 rows x 9724 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_embedding = model_mf.user_embedding.weight.data.detach().cpu().numpy()\n",
    "item_embedding = model_mf.item_embedding.weight.data.detach().cpu().numpy()\n",
    "user_biase_embedding = np.squeeze(model_mf.user_bias_embedding.weight.data.detach().cpu().numpy())\n",
    "item_biase_embedding = np.squeeze(model_mf.item_bias_embedding.weight.data.detach().cpu().numpy())\n",
    "\n",
    "predict = pd.DataFrame(\n",
    "    getPredictedFullMatrix(user_embedding, item_embedding, global_mean, user_biase_embedding, item_biase_embedding),\n",
    "    columns = data.set_movies,\n",
    "    index = data.set_users\n",
    ")\n",
    "\n",
    "predict"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
